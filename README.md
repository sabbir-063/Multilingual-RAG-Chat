# Multilingual RAG Chat

A FastAPI-based Retrieval-Augmented Generation (RAG) system that combines document indexing and question answering using Google's Gemini AI. This project enables users to upload documents, index them, and ask questions about their content.

## Features

- 📚 Document Indexing: Support for uploading and indexing multiple document types
- 🔍 Semantic Search: Utilizes FAISS for efficient vector similarity search
- 🤖 Gemini AI Integration: Powered by Google's Gemini AI for natural language understanding
- 🚀 FastAPI Backend: High-performance asynchronous API with automatic OpenAPI documentation
- 💾 Persistent Storage: Saves indexed documents for future use

## Prerequisites

- Python 3.11+
- Google Cloud API Key (for Gemini AI)
- FAISS for vector similarity search
- Sentence Transformers for embeddings

## Installation

1. Clone the repository:
```bash
git clone https://github.com/sabbir-063/Multilingual-RAG-Chat.git
cd Multilingual-RAG-Chat
```

2. Create a virtual environment and activate it:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Create a `.env` file in the project root and add your Gemini API key:
```env
GEMINI_API_KEY=your_api_key_here
```

## Usage

1. Start the FastAPI server:
```bash
uvicorn app:app --reload
```

2. The API will be available at `http://localhost:8000`

3. Access the interactive API documentation at `http://localhost:8000/docs`

### API Endpoints

#### Upload and Index Documents
```http
POST /index/
```
- Upload one or more files to be indexed
- Files will be stored in the `uploads` directory and processed for retrieval

#### Ask Questions
```http
GET /ask/?query=your_question&k=3
```
- `query`: Your question about the indexed documents
- `k`: Number of relevant document chunks to retrieve (default: 3)
- Returns an answer generated by Gemini AI along with source information

## Project Structure

```
├── app.py              # FastAPI application and endpoints
├── embedding_client.py # Handles document embeddings
├── gemini_client.py    # Gemini AI integration
├── loaders.py         # Document loading utilities
├── pipeline.py        # RAG pipeline implementation
├── vector_store.py    # FAISS vector store management
├── data/              # Directory for source documents
├── rag_store/         # Storage for FAISS index and metadata
└── uploads/           # Directory for uploaded files
```

## Future Enhancements

- [ ] Support for more document formats
- [ ] Improved document chunking strategies
- [ ] Real-time chat interface
- [ ] Document metadata management
- [ ] Enhanced error handling and validation
- [ ] Integration tests

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Google Gemini AI for providing the language model capabilities
- FAISS library for efficient similarity search
- Sentence Transformers for document embeddings
- FastAPI for the web framework
